"""
    LRhoSparseOpProblem <: AbstractProblem

Problem or finding the steady state of a â„’dagâ„’ matrix by computing
ð’ž = âˆ‘|Ï(Ïƒ)|Â²|âŸ¨âŸ¨Ïƒ|â„’ |ÏâŸ©âŸ©|Â² only storing H and c_ops.

DO NOT USE WITH COMPLEX-WEIGHT NETWORKS, AS IT DOES NOT WORK
"""
struct LRhoSparseOpProblem{B, SM} <: LRhoSquaredProblem where {B<:Basis,
                                                 SM<:SparseMatrixCSC}
    HilbSpace::B            # 0
    HnH::SM
    HnH_t::SM
    L_ops::Vector{SM}       # 4
    L_ops_h::Vector{SM}     # 4
    L_ops_t::Vector{SM}     # 5
    Ïss
end

"""
    LRhoSparseOpProblem([T=STD_REAL_PREC], args...)

Creates a problem for minimizing the cost function ð’ž = âˆ‘|Ï(Ïƒ)|Â²|âŸ¨âŸ¨Ïƒ|â„’ |ÏâŸ©âŸ©|Â².
Computes |âŸ¨âŸ¨Ïƒ|â„’ |ÏâŸ©âŸ©| by computing on the fly the commutator with the
Hamiltonian and with the collapse operators.

`args...` can either be a `GraphLindbladian`, or the Hamiltonian and a vector
of collapse operators.

`T=STD_REAL_PREC` by default is the numerical precision used. It should match that of
the network.
"""
LRhoSparseOpProblem(args...) = LRhoSparseOpProblem(STD_REAL_PREC, args...)
LRhoSparseOpProblem(T::Type{<:Number}, gl::GraphLindbladian) =
    LRhoSparseOpProblem(T, basis(gl), SparseOperator(hamiltonian(gl)), jump_operators(gl))
LRhoSparseOpProblem(T::Type{<:Number}, Ham::DataOperator, cops::Vector) =
    LRhoSparseOpProblem(T, Ham.basis_l, Ham, cops)
function LRhoSparseOpProblem(T::Type{<:Number}, Hilb::Basis, Ham::DataOperator, c_ops_q::Vector)
    # Fix complex numbers
    if real(T) == T
        T = Complex{T}
    end

    # Generate H_eff
    H_eff   = deepcopy(T.(Ham.data))
    ST = typeof(H_eff)

    c_ops       = Vector{ST}(undef, length(c_ops_q))
    c_ops_h     = Vector{ST}(undef, length(c_ops_q))
    c_ops_trans = Vector{ST}(undef, length(c_ops_q))
    for i=1:length(c_ops)
        c_ops[i]       = c_ops_q[i].data
        c_ops_h[i]     = c_ops[i]'
        c_ops_trans[i] = transpose(c_ops[i])
        H_eff         -= 0.5im * (c_ops[i]'*c_ops[i])
    end

    LRhoSparseOpProblem{typeof(Hilb), ST}(Hilb,                  # 0
                    H_eff,
                    transpose(H_eff),
                    c_ops,
                    c_ops_h,
                    c_ops_trans,
                    0.0)
end

basis(prob::LRhoSparseOpProblem) = prob.HilbSpace

function compute_Cloc!(LLO_i, âˆ‡lnÏˆ, prob::LRhoSparseOpProblem, net::MatrixNet, ð,
                      lnÏˆ=net(ð), ðp=deepcopy(ð))
    HnH = prob.HnH
    HnH_t = prob.HnH_t
    c_ops = prob.L_ops
    c_ops_h = prob.L_ops_h
    c_ops_trans = prob.L_ops_t

    Ïƒ  = row(ð)
    Ïƒt = col(ð)
    set_index!(ðp, index(ð))
    ðp_row = row(ðp)
    ðp_col = col(ðp)

    for el=LLO_i
      el .= 0.0
    end

    i_Ïƒt = index(Ïƒt)
    i_Ïƒ  = index(Ïƒ)

    C_loc = zero(Complex{real(out_type(net))})

    # âŸ¨Ïƒ|HÏ|ÏƒtâŸ© (using hermitianity of HdH)
    set!(ðp_col, toint(Ïƒt))
    for row_id = HnH_t.colptr[i_Ïƒ]:(HnH_t.colptr[i_Ïƒ+1]-1)
      i_Ïƒ_p = HnH_t.rowval[row_id]
      set_index!(ðp_row, i_Ïƒ_p)
      lnÏˆ_i, âˆ‡lnÏˆ_i = logÏˆ_and_âˆ‡logÏˆ!(âˆ‡lnÏˆ, net, ðp)
      C_loc_i  =  -1.0im * HnH_t.nzval[row_id] * exp(lnÏˆ_i - lnÏˆ)

      for (LLOave, _âˆ‡lnÏˆ)= zip(LLO_i, âˆ‡lnÏˆ_i.tuple_all_weights)
        LLOave .+= C_loc_i .* _âˆ‡lnÏˆ
      end
      C_loc  += C_loc_i
     end

    # âŸ¨Ïƒ|ÏHá´´|ÏƒtâŸ©
    set!(ðp_row, toint(Ïƒ))
    for row_id = HnH.colptr[i_Ïƒt]:(HnH.colptr[i_Ïƒt+1]-1)
      i_Ïƒ_p = HnH.rowval[row_id]
      set_index!(ðp_col, i_Ïƒ_p)
      lnÏˆ_i, âˆ‡lnÏˆ_i = logÏˆ_and_âˆ‡logÏˆ!(âˆ‡lnÏˆ, net, ðp)
      C_loc_i  =  1.0im * conj(HnH_t.nzval[row_id]) * exp(lnÏˆ_i - lnÏˆ)

      for (LLOave, _âˆ‡lnÏˆ)= zip(LLO_i, âˆ‡lnÏˆ_i.tuple_all_weights)
        LLOave .+= C_loc_i .* _âˆ‡lnÏˆ
      end
      C_loc  += C_loc_i
    end

    # L rho Ldag H #ok
    # -im âŸ¨Ïƒ|L Ï Lá´´|ÏƒtâŸ©
    for i=1:length(c_ops_h)
      Ld  = c_ops_h[i]
      L   = c_ops_trans[i]

      for ext_row_id = L.colptr[i_Ïƒ]:(L.colptr[i_Ïƒ+1]-1)
        i_Ïƒ_p = L.rowval[ext_row_id]
        set_index!(ðp_row, i_Ïƒ_p)
        val_Ïƒ_p = L.nzval[ext_row_id]

        for int_row_id = Ld.colptr[i_Ïƒt]:(Ld.colptr[i_Ïƒt+1]-1)
          i_Ïƒt_p = Ld.rowval[int_row_id]
          set_index!(ðp_col, i_Ïƒt_p)

          lnÏˆ_i, âˆ‡lnÏˆ_i = logÏˆ_and_âˆ‡logÏˆ!(âˆ‡lnÏˆ, net, ðp)
          C_loc_i  =  val_Ïƒ_p * Ld.nzval[int_row_id] *  exp(lnÏˆ_i - lnÏˆ)

          for (LLOave, _âˆ‡lnÏˆ)= zip(LLO_i, âˆ‡lnÏˆ_i.tuple_all_weights)
            LLOave .+= C_loc_i .* _âˆ‡lnÏˆ
          end
          C_loc  += C_loc_i
        end
      end
    end

    return C_loc
end

# pretty printing
Base.show(io::IO, p::LRhoSparseOpProblem) = print(io,
    "LRhoSparseOpProblem on space : $(basis(p)) computing the variance of Lrho using sparse H, c_ops")
