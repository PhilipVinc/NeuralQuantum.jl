var documenterSearchIndex = {"docs":
[{"location":"optimizers/#Optimizers-1","page":"Optimizers","title":"Optimizers","text":"","category":"section"},{"location":"optimizers/#","page":"Optimizers","title":"Optimizers","text":"An optimizer is a routine designed to update some parameters W using a gradient ∇ according to some formula. An optimizer is always needed when solving for the steady state of a Density Matrix.","category":"page"},{"location":"optimizers/#","page":"Optimizers","title":"Optimizers","text":"The most basic type of Optimizer is the Steepest-Gradient-Descent ( also known as Stochastic Gradient Descent - SGD ), which updates the weights W_i following the gradient nabla = nabla_W E, computed as the gradient of the objective function E against the parameters W. The update formula is:","category":"page"},{"location":"optimizers/#","page":"Optimizers","title":"Optimizers","text":"W_i+1 = W_i - epsilon nabla","category":"page"},{"location":"optimizers/#","page":"Optimizers","title":"Optimizers","text":"where the only parameter of the optimizer (hyperparameter, in Machine-Learning jargon) is the step size epsilon.","category":"page"},{"location":"optimizers/#","page":"Optimizers","title":"Optimizers","text":"There exist some way to improve upon this formula, for example by including momentum and friction, obtaining the Momentum Gradient Descent.","category":"page"},{"location":"optimizers/#Types-of-Optimizers-1","page":"Optimizers","title":"Types of Optimizers","text":"","category":"section"},{"location":"optimizers/#Gradient-Descent-(GD)-1","page":"Optimizers","title":"Gradient Descent (GD)","text":"","category":"section"},{"location":"optimizers/#","page":"Optimizers","title":"Optimizers","text":"Optimisers.Descent","category":"page"},{"location":"optimizers/#NeuralQuantum.Optimisers.Descent","page":"Optimizers","title":"NeuralQuantum.Optimisers.Descent","text":"Descent(η)\n\nClassic gradient descent optimiser with learning rate η. For each parameter p and its gradient δp, this runs p -= η*δp.\n\n\n\n\n\n","category":"type"},{"location":"optimizers/#Gradient-Descent-with-Corrected-Momentum-(NesterovGD)-1","page":"Optimizers","title":"Gradient Descent with Corrected Momentum (NesterovGD)","text":"","category":"section"},{"location":"optimizers/#","page":"Optimizers","title":"Optimizers","text":"Optimisers.Nesterov","category":"page"},{"location":"networks/#Neural-Network-Quantum-states-1","page":"Networks","title":"Neural Network Quantum states","text":"","category":"section"},{"location":"networks/#","page":"Networks","title":"Networks","text":"","category":"page"},{"location":"networks/#Pure-State-Networks-1","page":"Networks","title":"Pure State Networks","text":"","category":"section"},{"location":"networks/#Neural-Quantum-State-1","page":"Networks","title":"Neural Quantum State","text":"","category":"section"},{"location":"networks/#","page":"Networks","title":"Networks","text":"This is an implementation of a Neural Quantum State, a simple RBM state as proposed by Carleo et Troyer Science 2018. Please note that you can chose the activation function (the third argument, f) to be either a softplus function af_softplus or a logcosh function af_logcosh. The best performance is found by combining logcosh with a spin-like hilbert space.","category":"page"},{"location":"networks/#","page":"Networks","title":"Networks","text":"RBM","category":"page"},{"location":"networks/#NeuralQuantum.RBM","page":"Networks","title":"NeuralQuantum.RBM","text":"RBMSplit([T=Complex{STD_REAL_PREC}], N, α, f=af_softplus, [initW, initb])\n\nConstructs a Restricted Bolzmann Machine to encode a wavefunction, with weights of type T, N input neurons and αN hidden neurons. This is the Neural Quantum State (NQS) Ansatz of [1].\n\nN must match the size of the lattice.\n\nBy default the activation function is a sigmoid. You can also use logcosh by passing as an additional parameter af_logcosh.\n\nThe initial parameters of the neurons are initialized with a rescaled normal distribution of width 0.01 for the coupling matrix and 0.05 for the local biases. The default initializers can be overriden by specifying\n\ninitW=(dims...)->rescalednormal(T, 0.01, dims...) initb=(dims...)->rescalednormal(T, 0.05, dims...) inita=(dims...)->rescaled_normal(T, 0.01, dims...)\n\nRefs:     https://arxiv.org/abs/1606.02318\n\n\n\n\n\n","category":"type"},{"location":"networks/#","page":"Networks","title":"Networks","text":"","category":"page"},{"location":"networks/#Mixed-State-Networks-1","page":"Networks","title":"Mixed State Networks","text":"","category":"section"},{"location":"networks/#","page":"Networks","title":"Networks","text":"In general, given an Hilbert space mathcalH with basis vecsigmainmathcalH, a density matrix defined on this space lives in the space of the Bounded Operators mathcalB with (overcomplete) basis (sigma tildesigma ) in mathcalHotimesmathcalH.  A network is a (high-dimensional non-linear) function","category":"page"},{"location":"networks/#","page":"Networks","title":"Networks","text":"rho(sigma tildesigma W)","category":"page"},{"location":"networks/#","page":"Networks","title":"Networks","text":"depending on the variational parameters W, and on the entries of the density matrix labelled by (sigma tildesigma).","category":"page"},{"location":"networks/#Neural-Density-Matrix-1","page":"Networks","title":"Neural Density Matrix","text":"","category":"section"},{"location":"networks/#","page":"Networks","title":"Networks","text":"Torlai et Melko PRL 2019","category":"page"},{"location":"networks/#","page":"Networks","title":"Networks","text":"A real-valued neural network to describe a positive-semidefinite matrix. Complex numbers are generated by duplicating the structure of the network, and using one to generate the modulus and the other to generate the phase. See the article for details.","category":"page"},{"location":"networks/#","page":"Networks","title":"Networks","text":"NDM","category":"page"},{"location":"networks/#NeuralQuantum.NDM","page":"Networks","title":"NeuralQuantum.NDM","text":"NDM([T=STD_REAL_PREC], N, αₕ, αₐ, f=af_softplus, [initW, initb, inita])\n\nConstructs a Neural Density Matrix with numerical precision T (Defaults to Float32), N input neurons, N⋅αₕ hidden neurons and N⋅αₐ ancillary neurons. This network ensure that the density matrix is always positive definite.\n\nThe number of input neurons N must match the size of the lattice.\n\nBy default the activation function is a sigmoid. You can also use logcosh by     passing as an additional parameter af_logcosh.\n\nThe initial parameters of the neurons are initialized with a rescaled normal distribution of width 0.01 for the coupling matrix and 0.005 for the local biases. The default initializers can be overriden by specifying\n\ninitW=(dims...)->rescalednormal(T, 0.01, dims...), initb=(dims...)->rescalednormal(T, 0.005, dims...), inita=(dims...)->rescaled_normal(T, 0.005, dims...))\n\nRefs:     https://arxiv.org/abs/1801.09684     https://arxiv.org/abs/1902.10104\n\n\n\n\n\n","category":"type"},{"location":"networks/#RBM-Density-Matrix-1","page":"Networks","title":"RBM Density Matrix","text":"","category":"section"},{"location":"networks/#","page":"Networks","title":"Networks","text":"A simple state that does not preserve positivity, but which is hermitian.","category":"page"},{"location":"networks/#","page":"Networks","title":"Networks","text":"RBMSplit","category":"page"},{"location":"networks/#NeuralQuantum.RBMSplit","page":"Networks","title":"NeuralQuantum.RBMSplit","text":"RBMSplit([T=Complex{STD_REAL_PREC}], N, α, [initW, initb, inita])\n\nConstructs a Restricted Bolzmann Machine to encode a vectorised density matrix, with weights of type T (Defaults to ComplexF32), 2N input neurons, 2N⋅α hidden neurons. This network does not ensure positive-definitness of the density matrix.\n\nN must match the size of the lattice.\n\nThe initial parameters of the neurons are initialized with a rescaled normal distribution of width 0.01 for the coupling matrix and 0.05 for the local biases. The default initializers can be overriden by specifying\n\ninitW=(dims...)->rescalednormal(T, 0.01, dims...), initb=(dims...)->rescalednormal(T, 0.05, dims...), initb=(dims...)->rescaled_normal(T, 0.01, dims...),\n\nRefs:     https://arxiv.org/abs/1902.07006\n\n\n\n\n\n","category":"type"},{"location":"basics/#Basics-1","page":"Basics","title":"Basics","text":"","category":"section"},{"location":"basics/#Defining-the-problem-1","page":"Basics","title":"Defining the problem","text":"","category":"section"},{"location":"basics/#","page":"Basics","title":"Basics","text":"NeuralQuantum's aim is to compute the steady state of an Open Quantum System or the ground state of an Hamiltonian system. As such, the first step must be defining the quantum system you are interested in.","category":"page"},{"location":"basics/#Hilbert-space-1","page":"Basics","title":"Hilbert space","text":"","category":"section"},{"location":"basics/#","page":"Basics","title":"Basics","text":"First, you should pick an hilbert space. As of now, only homogeneous Hilbert spaces are supported, HomogeneousFock or HomogeneousSpin If you wish, for example, to model 5 spin-1/2 particles you can create the Hilbert space as follows:","category":"page"},{"location":"basics/#","page":"Basics","title":"Basics","text":"julia> using NeuralQuantum\n\njulia> N = 5;\njulia> hilb = HomogeneousSpin(N, 1//2)\nHilbert Space with 5 identical spins 1/2 of dimension 2\n\njulia> shape(hilb)\n5-element Array{Int64,1}:\n 2 2 2 2 2\n\njulia> state(hilb)\n5-element Array{Float32,1}:\n -1.0 -1.0 -1.0 -1.0 -1.0","category":"page"},{"location":"basics/#","page":"Basics","title":"Basics","text":"!!! Spin vs Fock Space    You could also model the space as a Fock space with local dimension 2. This choice is formally equivalent, but in this case the states don't have values [-1.0, 1.0] but will take on the values [0.0, 1.0]. This can be useful sometimes when working with some networks. In general, the spin-space works better with logcosh activation function, while fock space works better with softplus activation function.","category":"page"},{"location":"basics/#Building-an-Hamiltonian-1","page":"Basics","title":"Building an Hamiltonian","text":"","category":"section"},{"location":"basics/#","page":"Basics","title":"Basics","text":"To build an hamiltonian, you cannot use simple matrices. Instead, you should use our custom format that behaves similarly to a sparse matrix, but has a few additional tricks that allows us to be efficient in the kind of calculations that Variational Monte Carlo requires. To build an Hamiltonian, the simplest way is to use the standard pauli-matrices and bosonic creation/destruction operators, and compose them:","category":"page"},{"location":"basics/#","page":"Basics","title":"Basics","text":"julia> h = 1.0; J=1.0;\njulia> H = LocalOperator(hilb)\nempty KLocalOperator on space:  HomogeneousSpin(5, 2)\n\njulia> for i=1:N\n         global H  -= h * sigmax(hilb, i)\n       end\nKLocalOperatorSum:\n   -sites: Array{Int64,1}[[1], [2], [3], [4], [5]]\n\njulia> for i=1:N\n         global H  += J * sigmaz(hilb, i) * sigmaz(hilb, mod(i, N)+1)\n       end\nKLocalOperatorSum:\n  -sites: Array{Int64,1}[[1], [2], [3], [4], [5], [1, 2], [2, 3], [3, 4], [4, 5], [1, 5]]","category":"page"},{"location":"basics/#","page":"Basics","title":"Basics","text":"The built-in operators are sigmax, sigmay, sigmaz, sigmap,  sigmam and create, destroy. They support all the standard operations (transpose, conjugate, conjugate transpose).","category":"page"},{"location":"basics/#","page":"Basics","title":"Basics","text":"You can also create your custom N-body operators, by specifying an hilbert space, the list of sites upon which it acts, and the matrix in the reduced space of the sites where it acts. For example, to build by yourself the sigmaz_1 * sigmaz_2 operator you can do the following:","category":"page"},{"location":"basics/#","page":"Basics","title":"Basics","text":"julia> sites = [1,2]\njulia> mat = diagm(0=>[1.0, -1.0, -1.0, 1.0])\njulia> KLocalOperatorRow(hilb, [1,2],  complex.(mat))\nKLocalOperator(Complex{Float64})\n  Hilb: HomogeneousSpin(5, 2)\n  sites: [1, 2]  (size: [2, 2])\n 1.0 + 0.0im   0.0 + 0.0im   0.0 + 0.0im  0.0 + 0.0im\n 0.0 + 0.0im  -1.0 + 0.0im   0.0 + 0.0im  0.0 + 0.0im\n 0.0 + 0.0im   0.0 + 0.0im  -1.0 + 0.0im  0.0 + 0.0im\n 0.0 + 0.0im   0.0 + 0.0im   0.0 + 0.0im  1.0 + 0.0im","category":"page"},{"location":"basics/#Choosing-a-Neural-Network-State-1","page":"Basics","title":"Choosing a Neural Network State","text":"","category":"section"},{"location":"basics/#","page":"Basics","title":"Basics","text":"You should pick a state from those listed in Networks. In the following we will pick a simple restricted Boltmann Machine (RBM).","category":"page"},{"location":"basics/#","page":"Basics","title":"Basics","text":"net  = RBM(Float32, N, 1, af_logcosh)","category":"page"},{"location":"basics/#","page":"Basics","title":"Basics","text":"In general, when working with neural networks, the first argument is an optional type for the parameters, the second is the number of sites in the system, and the others depend on the network. In the case of the RBM, the third argument is the density of the hidden layer, and the last argument is the activation function. In general we have seen that best performance is found by combining logcosh activation with spin-hilbert spaces.","category":"page"},{"location":"basics/#","page":"Basics","title":"Basics","text":"When you create a network, it has all it's weights distributed according to a gaussian with standard deviation 0.005. You can also reinitialize all weights with a gaussian distribution by using the command init_random_pars!.","category":"page"},{"location":"basics/#","page":"Basics","title":"Basics","text":"julia> init_random_pars!(net, sigma=0.01)","category":"page"},{"location":"basics/#Chosing-a-sampler-1","page":"Basics","title":"Chosing a sampler","text":"","category":"section"},{"location":"basics/#","page":"Basics","title":"Basics","text":"The sampler is the algorithm that selects the states in the hilbert space to be summed over. Options are ExactSampler, which computes the whole probability distribution and samples exactly, but is very expensive and only works for relatively small (N<10) systems.","category":"page"},{"location":"basics/#","page":"Basics","title":"Basics","text":"In general, you will be using a MetropolisSampler, which uses a Metropolis-Hastings Markov Chain with a specific transition rule. Currently only a simple switching rule and an exchange rule are implemented.","category":"page"},{"location":"basics/#","page":"Basics","title":"Basics","text":"sampler = MetropolisSampler(LocalRule(), 125, N, burn=100)","category":"page"},{"location":"basics/#","page":"Basics","title":"Basics","text":"The first argument is the rule, the second argument is the length of each chain, the third argument is the number of times the LocalRule should be applied at every iteration (and should be of the order N). burn is an optional keyword argument with the number of unused iterations after the chain is resetted.","category":"page"},{"location":"basics/#Stochastic-Reconfiguration-1","page":"Basics","title":"Stochastic Reconfiguration","text":"","category":"section"},{"location":"basics/#","page":"Basics","title":"Basics","text":"While it is possible to find the ground state with simple gradient descent, much better efficiency is achieved when the networks have less than 5000 parameters by using Natural Gradient Descent, or Stochastic Reconfiguration, which is somewhat equivalent to a second order newton method.","category":"page"},{"location":"basics/#","page":"Basics","title":"Basics","text":"The stochastic reconfiguration essentially builds a local approximation of the metric, called S-matrix, and solves the equation delta x = S^-1 nabla C where C is the cost function (the energy). This equation can be solved either by inversion or by using an iterative solver, which is much more efficient. Type ?SR in julia to see it's documentation.","category":"page"},{"location":"basics/#","page":"Basics","title":"Basics","text":"algo  = SR(ϵ=(0.1), algorithm=sr_cg, precision=1e-3)","category":"page"},{"location":"basics/#","page":"Basics","title":"Basics","text":"Notable arguments are ϵ, which is the diagonal shift of the S matrix when inverting, the precision of the iterative solver and the algorithm used.","category":"page"},{"location":"basics/#Solving-the-problem-1","page":"Basics","title":"Solving the problem","text":"","category":"section"},{"location":"basics/#","page":"Basics","title":"Basics","text":"All is set. You now only need to construct a BatchedSampler (which is a weird name for the object actually effecting the sampling) and optimise the weights","category":"page"},{"location":"basics/#","page":"Basics","title":"Basics","text":"is = BatchedSampler(net, sampl, H, algo; batch_sz=8)\noptimizer = Optimisers.Descent(0.1)\n\nEvalues = Float64[];\nEerr = Float64[];\nfor i=1:300\n    ldata, prec = sample!(is)\n    ob = compute_observables(is)\n\n    push!(Evalues, real(ldata.mean))\n    push!(Eerr, ldata.error)\n    grad = precondition!(prec, algo, i)\n    Optimisers.update!(optimizer, net, grad)\nend","category":"page"},{"location":"basics/#","page":"Basics","title":"Basics","text":"That's it. At every iteration sample!(is) will return two elements: the value of the cost function (with it's error) and an object containing data to compute the gradient, which is computed by precondition!.","category":"page"},{"location":"basics/#Computing-Observables-1","page":"Basics","title":"Computing Observables","text":"","category":"section"},{"location":"basics/#","page":"Basics","title":"Basics","text":"If you wish to compute observables, you simply need to compose the operator that represent the observable, and then add it to the BatchedSampler by doing","category":"page"},{"location":"basics/#","page":"Basics","title":"Basics","text":"julia> Sx = LocalOperator(hilb)\njulia> for i=1:N\n          global Sx += sigmax(hilb, i)/N\n       end\n\njulia> add_observable!(is, \"Sx\", Sx)","category":"page"},{"location":"basics/#","page":"Basics","title":"Basics","text":"From now on, if you call compute_observables(is) you will obtain a dictionary with all the observables computed. Observables are computed by using the same Markov Chain used to estimate the energy (cost function) to be minimised for hamiltonian systems. In the case of Open Quantum Systems a different markov chain is used.","category":"page"},{"location":"liouvillian/#Liouvillian-Master-Equation-1","page":"Liouvillian","title":"Liouvillian Master Equation","text":"","category":"section"},{"location":"liouvillian/#","page":"Liouvillian","title":"Liouvillian","text":"The Lindblad master equation","category":"page"},{"location":"liouvillian/#","page":"Liouvillian","title":"Liouvillian","text":"requirephysics\nfract hatrhodt = mathcalLhatrho = - i lefthatH hatrhoright + sum_ileft( hatL_ihatrhohatL^dagger_i - frac12lefthatL^dagger_ihatL_ihatrhorightright)","category":"page"},{"location":"liouvillian/#","page":"Liouvillian","title":"Liouvillian","text":"is completely encoded within the Liouvillian mathcalL. To build it, you must first define the Hamiltonian and a vector containing the jump/Loss operators, and then use the function liouvillian, as shown below.","category":"page"},{"location":"liouvillian/#","page":"Liouvillian","title":"Liouvillian","text":"julia> N = 7\njulia> hilb = HomogeneousSpin(N,1//2)\n\njulia> ops = []\n0-element Array{Any,1}\n\njulia> H = LocalOperator(hilb)\nempty KLocalOperator on space:  HomogeneousFock(7, 2)\n\njulia> for i=1:N\n           global H += g/2.0 * sigmax(hilb, i)\n           global H += V/4.0 * sigmaz(hilb, i) * sigmaz(hilb, mod(i, N)+1)\n\n           push!(ops, sigmam(hilb, i))\n       end\n\njulia> liouv = liouvillian(H, ops)\nKLocalLiouvillian(ComplexF64)\n  Hilb: SuperOpSpace(HomogeneousFock(7, 2)))","category":"page"},{"location":"liouvillian/#","page":"Liouvillian","title":"Liouvillian","text":"The liouvillian behaves as most other operators, even though you cannot (at the moment) do further algebraic operations on it.","category":"page"},{"location":"liouvillian/#","page":"Liouvillian","title":"Liouvillian","text":"Like any other operator, you can convert it to a Matrix or SparseMatrix by calling the standard Julia conversion methods.","category":"page"},{"location":"liouvillian/#","page":"Liouvillian","title":"Liouvillian","text":"julia> Matrix(liouv)\n\njulia> sparse(liouv)","category":"page"},{"location":"liouvillian/#","page":"Liouvillian","title":"Liouvillian","text":"Those can be used to convert the lindbladian to formats used by other packages, such as QuantumOptics.jl.","category":"page"},{"location":"liouvillian/#Steady-States-of-Open-Quantum-Systems-1","page":"Liouvillian","title":"Steady States of Open Quantum Systems","text":"","category":"section"},{"location":"liouvillian/#","page":"Liouvillian","title":"Liouvillian","text":"The steady state of an Open Quantum System is computed by minimising the expectation value of","category":"page"},{"location":"liouvillian/#","page":"Liouvillian","title":"Liouvillian","text":"mathcalC = fractextTrlefthatrho^daggermathcalL^daggermathcalLhatrhorighttextTrlefthatrho^daggerhatrhoright","category":"page"},{"location":"liouvillian/#","page":"Liouvillian","title":"Liouvillian","text":"When stochastically sampling this cost function on the hilbert space, it is computed as","category":"page"},{"location":"liouvillian/#","page":"Liouvillian","title":"Liouvillian","text":"mathcalC = sum_sigma p(sigma tildesigma) leftleft(mathcalLhatrhoright)(sigma tildesigma)right^2","category":"page"},{"location":"liouvillian/#","page":"Liouvillian","title":"Liouvillian","text":"which has the 0-variance property. The Markov chain is performed according to the probability p(sigma tildesigma) = rho(sigma tildesigma)^2Z with Z=sumrho(sigma tildesigma)^2.","category":"page"},{"location":"reference/#Reference-1","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"reference/#","page":"Reference","title":"Reference","text":"This is the reference to the public interface of NeuralQuantum.","category":"page"},{"location":"reference/#Hilbert-spaces-1","page":"Reference","title":"Hilbert spaces","text":"","category":"section"},{"location":"reference/#","page":"Reference","title":"Reference","text":"Methods relative to Hilbert spaces and their states","category":"page"},{"location":"reference/#General-methods-1","page":"Reference","title":"General methods","text":"","category":"section"},{"location":"reference/#","page":"Reference","title":"Reference","text":"nsites\nNeuralQuantum.shape\nNeuralQuantum.local_dim\nNeuralQuantum.spacedimension\nNeuralQuantum.indexable\nNeuralQuantum.is_homogeneous","category":"page"},{"location":"reference/#NeuralQuantum.nsites","page":"Reference","title":"NeuralQuantum.nsites","text":"nsites(hilbert) -> Int\n\nReturns the number of lattice sites in the Hilbert space.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NeuralQuantum.shape","page":"Reference","title":"NeuralQuantum.shape","text":"shape(hilbert) -> Vector{Int}\n\nReturns a vector containing the local hilbert space dimensions of every mode in the Hilbert space.\n\nIn the case of homogeneous spaces, it is usually more efficient to call local_dim.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NeuralQuantum.local_dim","page":"Reference","title":"NeuralQuantum.local_dim","text":"local_dim(hilbert [, i]) -> Int\n\nReturns the local dimension of the hilbert space on site i. If the space is homogeneous then specifying i is not needed.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NeuralQuantum.spacedimension","page":"Reference","title":"NeuralQuantum.spacedimension","text":"spacedimension(hilbert) = prod(shape(hilbert)) -> Int\n\nReturns the total dimension of the vector space hilbert. This is only valid if indexable(hilbert) == true, otherwise it's 0.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NeuralQuantum.indexable","page":"Reference","title":"NeuralQuantum.indexable","text":"indexable(hilbert) -> Bool\n\nReturns true if the space is can be indexed with an Int64, which means that htis tests true when\n\n    spacedimension(hilbert) <= typemax(Int64)\n\n\n\n\n\n","category":"function"},{"location":"reference/#NeuralQuantum.is_homogeneous","page":"Reference","title":"NeuralQuantum.is_homogeneous","text":"is_homogeneous(hilbert) -> Bool\n\nReturns true if the space is homogeneous, that is, if all the modes have the same local hilbert space dimension.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Constructors-1","page":"Reference","title":"Constructors","text":"","category":"section"},{"location":"reference/#","page":"Reference","title":"Reference","text":"HomogeneousFock\nHomogeneousSpin","category":"page"},{"location":"reference/#NeuralQuantum.HomogeneousFock","page":"Reference","title":"NeuralQuantum.HomogeneousFock","text":"HomogeneousFock(N, m; excitations=N*m)\n\nConstructs the Hilbert space of N identical modes with m levels. If \"n_exc\" is set, then the total number of excitations is bounded when generating a state.\n\n!!!note     If using a sampler that does not respect the symmetries of the system,     the n_exc will not be respected during sampling.\n\n\n\n\n\n","category":"type"},{"location":"reference/#NeuralQuantum.HomogeneousSpin","page":"Reference","title":"NeuralQuantum.HomogeneousSpin","text":"HomogeneousSpins(N, S::Rational=1//2)\n\nConstructs the Hilbert space of N identical spins-S (by default 1//2).\n\n\n\n\n\n","category":"type"},{"location":"reference/#Working-with-states-1","page":"Reference","title":"Working with states","text":"","category":"section"},{"location":"reference/#","page":"Reference","title":"Reference","text":"index\nstate\nstates\nRandom.rand!\nRandom.rand\napply!\nNeuralQuantum.flipat!\nNeuralQuantum.setat!\nNeuralQuantum.local_index\nNeuralQuantum.unsafe_get_el","category":"page"},{"location":"reference/#NeuralQuantum.index","page":"Reference","title":"NeuralQuantum.index","text":"index(hilb, state)\n\nConverts to an int the state of the hilbert space hilb assuming it's indexable.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NeuralQuantum.state","page":"Reference","title":"NeuralQuantum.state","text":"state([arrT=Vector], [T=STD_REAL_PREC], hilbert, [i=0])\n\nConstructs a state for the hilbert space with precision T and array type arrT. By default that's the lowest state, otherwise if the hilbert space it's indexable you can specify with a second argument.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NeuralQuantum.states","page":"Reference","title":"NeuralQuantum.states","text":"states(hilb) -> iterator\n\nReturns an iterator to iterate all states in the hilbert space\n\n\n\n\n\n","category":"function"},{"location":"reference/#NeuralQuantum.apply!","page":"Reference","title":"NeuralQuantum.apply!","text":"apply!(σ, changes)\n\nApplies the changes changes to the σ.\n\nIf state isa DoubleState then single-value changes are applied to the columns of the state (in order to compute matrix-operator products). Otherwise it should be a tuple with changes of row and columns.\n\nIf changes is nothing, does nothing.\n\n\n\n\n\napply!(state, changes, [changes_r] )\n\nApply the changes changes to the state. If state is a double state and changes is a tuple, then the first element of the tuple is the row-changes and the second element is the column-changes. Optionally the two elements of the tuple can be passed separately.\n\nIf the state is double but there is only 1 element of changes, it's applied to the rows.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NeuralQuantum.flipat!","page":"Reference","title":"NeuralQuantum.flipat!","text":"flipat!(state, hilb, i) -> (old_val, new_val)\n\nRandomly flips state[i] to another available state. Returns the old value of state[i] and the new value. state is changed in-place.\n\n\n\n\n\n","category":"function"},{"location":"reference/#NeuralQuantum.unsafe_get_el","page":"Reference","title":"NeuralQuantum.unsafe_get_el","text":"unsafe_get_el(state, [batch], el)\n\nGiven a vector of batches of states with size size(state) = [:, batches, els], take the batch group el, and if specified also selects one single batch.\n\nIt's somewhat equivalent to a view, but handles tuples of states for density matrices correctly and uses unsafe views to prevent allocation on CPU.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Operators-1","page":"Reference","title":"Operators","text":"","category":"section"},{"location":"reference/#","page":"Reference","title":"Reference","text":"sigmax\nsigmay\nsigmaz\nsigmap\nsigmam\ncreate\ndestroy\nKLocalOperator\nNeuralQuantum.KLocalOperatorRow\nNeuralQuantum.liouvillian","category":"page"},{"location":"reference/#QuantumOpticsBase.sigmax","page":"Reference","title":"QuantumOpticsBase.sigmax","text":"sigmax(hilbert::AbstractHilbert, site::Int)\n\nBuilds a σₓ operator acting on the site-th site of the Many body Hilbert space hilbert.\n\nNote: M-dimensional Hilbert spaces are treated as spin (M-1)//2 spins.\n\n\n\n\n\n","category":"function"},{"location":"reference/#QuantumOpticsBase.sigmay","page":"Reference","title":"QuantumOpticsBase.sigmay","text":"sigmay(hilbert::AbstractHilbert, site::Int)\n\nBuilds a σ_y operator acting on the site-th site of the Many body Hilbert space hilbert.\n\nNote: Hilbert must have local space dimension 2 on that site.\n\n\n\n\n\n","category":"function"},{"location":"reference/#QuantumOpticsBase.sigmaz","page":"Reference","title":"QuantumOpticsBase.sigmaz","text":"sigmaz(hilbert::AbstractHilbert, site::Int)\n\nBuilds a σ_z operator acting on the site-th site of the Many body Hilbert space hilbert.\n\nNote: M-dimensional Hilbert spaces are treated as spin (M-1)//2 spins.\n\n\n\n\n\n","category":"function"},{"location":"reference/#QuantumOpticsBase.sigmap","page":"Reference","title":"QuantumOpticsBase.sigmap","text":"sigmap(hilbert::AbstractHilbert, site::Int)\n\nBuilds a σ₊ operator acting on the site-th site of the Many body Hilbert space hilbert.\n\nNote: M-dimensional Hilbert spaces are treated as spin (M-1)//2 spins.\n\n\n\n\n\n","category":"function"},{"location":"reference/#QuantumOpticsBase.sigmam","page":"Reference","title":"QuantumOpticsBase.sigmam","text":"sigmam(hilbert::AbstractHilbert, site::Int)\n\nBuilds a σ₋ operator acting on the site-th site of the Many body Hilbert space hilbert.\n\nNote: M-dimensional Hilbert spaces are treated as spin (M-1)//2 spins.\n\n\n\n\n\n","category":"function"},{"location":"reference/#QuantumOpticsBase.create","page":"Reference","title":"QuantumOpticsBase.create","text":"create(hilbert::AbstractHilbert, site::Int)\n\nBuilds a bosonic creation operator acting on the site-th site of the Many body Hilbert space hilbert.\n\nNote: spin-m//2 spaces are treated as fock spaces with dimension m+1\n\n\n\n\n\n","category":"function"},{"location":"reference/#QuantumOpticsBase.destroy","page":"Reference","title":"QuantumOpticsBase.destroy","text":"destroy(hilbert::AbstractHilbert, site::Int)\n\nBuilds a bosonic destruction operator acting on the site-th site of the Many body Hilbert space hilbert.\n\nNote: spin-m//2 spaces are treated as fock spaces with dimension m+1\n\n\n\n\n\n","category":"function"},{"location":"reference/#NeuralQuantum.KLocalOperator","page":"Reference","title":"NeuralQuantum.KLocalOperator","text":"KLocalOperator\n\nA representation of a local operator, acting on certain sites, each with hilb_dims dimension. The local operator is written in matrix form in this basis as mat. For every row of mat there are several non-zero values contained in mel, and to each of those, to_change contains the sites that must change the basis new value, contained in new_value\n\n\n\n\n\n","category":"type"},{"location":"reference/#NeuralQuantum.KLocalOperatorRow","page":"Reference","title":"NeuralQuantum.KLocalOperatorRow","text":"KLocalOperatorRow(sites::Vector, hilb_dims::Vector, operator)\n\nCreates a KLocalOperator where connections are stored by row for the operator     operator acting on sites each with hilb_dims local dimension.\n\n\n\n\n\n","category":"function"},{"location":"reference/#QuantumOpticsBase.liouvillian","page":"Reference","title":"QuantumOpticsBase.liouvillian","text":"liouvillian(Ĥ, ops::Vector)\n\nConstructs the LocalOperator representation of a liouvillian super-operator with coherent part given by the hamilotnian Ĥ, and ops as the list of jump operators.\n\n\n\n\n\n","category":"function"},{"location":"states/#State-abstract-type-1","page":"State abstract type","title":"State abstract type","text":"","category":"section"},{"location":"states/#","page":"State abstract type","title":"State abstract type","text":"State is the base abstract type which must be subtyped for the elements that span an hilbert space (or a Matrix space), and which also correspond to a configuration of the visible layer of the neural network.","category":"page"},{"location":"states/#Defining-a-new-State-concrete-struct-1","page":"State abstract type","title":"Defining a new State concrete struct","text":"","category":"section"},{"location":"states/#","page":"State abstract type","title":"State abstract type","text":"It is possible that one wants to define a new type of state, which spans the density matrix space in a different way and gives a correspondence between visible layer configurations and elements in the density matrix in a novel way. To do so, one must take care of defining the following ingredients:     - The mutable struct holding the state itself;     - Accessor methods that can be used by the sampler and the problem to compute     observables;     - Methods for modyfing the state;     - (optionally) constructors.","category":"page"},{"location":"states/#","page":"State abstract type","title":"State abstract type","text":"a State derivating from DualValuedState must define the following:","category":"page"},{"location":"states/#","page":"State abstract type","title":"State abstract type","text":"mutable struct ExampleState <: DualValuedState\n\t...\n\t...\nend","category":"page"},{"location":"states/#Constructors-1","page":"State abstract type","title":"Constructors","text":"","category":"section"},{"location":"states/#","page":"State abstract type","title":"State abstract type","text":"No default constructor must be created by itself, because it will be called from specific code of every NeuralNetwork. Though, the standard interface would require to define","category":"page"},{"location":"states/#","page":"State abstract type","title":"State abstract type","text":"ExampleState{...}({number params}, {Ints })","category":"page"},{"location":"states/#","page":"State abstract type","title":"State abstract type","text":"where number params are all parameters listing the length of the various items in the ExampleState, and {Ints} are the ints that initialize them.","category":"page"},{"location":"states/#Accessors-1","page":"State abstract type","title":"Accessors","text":"","category":"section"},{"location":"states/#","page":"State abstract type","title":"State abstract type","text":"To define a new state, all those accessors must be defined:","category":"page"},{"location":"states/#","page":"State abstract type","title":"State abstract type","text":"spacedimension(state::ExampleState) returning the size of the space where this state lives. For example, for N spins this will be 2^N\nhalf_space_dimension(state::ExampleState) returns the size of the physical hilbert space where the density matrix is defined. Usually 2^(N/2)\ntoint(state::ExampleState) returning the state expressed as an integer\nnsites(state::ExampleState) returns the number of sites where this state is defined.\nvectorindex(state::ExampleState) ????\nneurontype(state::ExampleState) returning the type of the neuron for this state\nneurontype(::Type{ExampleState}) returning the type of the neuron for this state.","category":"page"},{"location":"states/#Operations-1","page":"State abstract type","title":"Operations","text":"","category":"section"},{"location":"states/#","page":"State abstract type","title":"State abstract type","text":"flipat!(state, i::Integer)\nset!(state, i::Integer)\nadd!(State, i::Integer)\n`setzero!(state)","category":"page"},{"location":"#NeuralQuantum.jl-:-Neural-Network-states-for-Quantum-Systems-1","page":"Home","title":"NeuralQuantum.jl : Neural Network states for Quantum Systems","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"NeuralQuantum.jl is a numerical framework written in Julia to investigate Neural-Network representations of pure and mixed quantum states, and to find the Steady-State of such (Open) Quantum Systems through MonteCarlo procedures. The package can also compute the ground state of a many-body hamiltonian.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"note: Note\nThis code is currently heavily in the making. v0.2 should mark a somewhat more stable interface, but it's very different from older versions. If you find this code interesting, I'd be glad if you could let me know and give me some feedback.","category":"page"},{"location":"#Installation-1","page":"Home","title":"Installation","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Download Julia 1.3 or a more recent version (we do not support older versions of Julia). To install NeuralQuantum, run in a Julia prompt the following command.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"] add https://github.com/PhilipVinc/NeuralQuantum.jl","category":"page"},{"location":"#Basic-Usage-1","page":"Home","title":"Basic Usage","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"CurrentModule = NeuralQuantum","category":"page"},{"location":"#","page":"Home","title":"Home","text":"When using NeuralQuantum, to determine the Ground State or Steady State of a many-body problem, one needs to perform the following choices:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Chose a Neural-Network based ansatz to approximate the quantum state (see Sec. Networks);\nChose whever you want to perform a standard (stochastic) gradient descent, or if you want to use Natural Gradient Descent (also known as Stochastic Reconfiguration) (see Sec. Algorithms);\nChose the optimizer to perform the optimization, such as steepest gradient, accelerated gradient or others (see Sec. Optimizers);","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Here you can find a very short, commented example. For a more in-depth walkthrough of NeuralQuantum.jl please refer to Sec. Basics.","category":"page"},{"location":"#Table-Of-Contents-1","page":"Home","title":"Table Of Contents","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"","category":"page"},{"location":"samplers/#Samplers-1","page":"Samplers","title":"Samplers","text":"","category":"section"},{"location":"samplers/#","page":"Samplers","title":"Samplers","text":"In v0.2 there are two types of monte carlo samplers implemented:","category":"page"},{"location":"samplers/#Exact-Sampler-1","page":"Samplers","title":"Exact Sampler","text":"","category":"section"},{"location":"samplers/#","page":"Samplers","title":"Samplers","text":"ExactSampler, to be used only for relatively small systems, constructs the full probability distribution and samples it directly. This has exponential memory cost.","category":"page"},{"location":"samplers/#","page":"Samplers","title":"Samplers","text":"The only parameter for this sampler is the number of desired samples and an optional starting seed.","category":"page"},{"location":"samplers/#Metropolis-sampler-1","page":"Samplers","title":"Metropolis sampler","text":"","category":"section"},{"location":"samplers/#","page":"Samplers","title":"Samplers","text":"MetropolisSampler, can be used on arbitrarily big system. It samples from a Markov Chain where states are updated according to the Metropolis-Hastings rule. In a nutshell, the Metropolis sampler starts from a state sampled from the system's hilbert space, then proposes a new state according to some rule, and accepts or rejects this new state depending on some probability.","category":"page"},{"location":"samplers/#","page":"Samplers","title":"Samplers","text":"MetropolisSampler takes 3 parameters: rule, chain_length and passes. The second, chain_length specifies how many samples should the chain have, while passes specifies how many times rule must be applied between two returned samples. The effective chain length will actually be chain_length * passes, but only a fraction will be returned, in order to reduce correlation among different samples.","category":"page"},{"location":"samplers/#","page":"Samplers","title":"Samplers","text":"For ergodicity, passes should always be even.","category":"page"},{"location":"samplers/#Metropolis-Rules-1","page":"Samplers","title":"Metropolis Rules","text":"","category":"section"},{"location":"samplers/#Local-1","page":"Samplers","title":"Local","text":"","category":"section"},{"location":"samplers/#","page":"Samplers","title":"Samplers","text":"LocalRule is a transition rule for Metropolis-Hastings sampling where at every step a random site is switched to another random state.","category":"page"},{"location":"samplers/#","page":"Samplers","title":"Samplers","text":"This rule does not preserve any particular property or symmetry of the hilbert space or of the operator.","category":"page"},{"location":"samplers/#Exchange-1","page":"Samplers","title":"Exchange","text":"","category":"section"},{"location":"samplers/#","page":"Samplers","title":"Samplers","text":"ExchangeRule is a transition rule for Metropolis-Hastings sampling where at every step a random couple of sites i,j is selected, and their states switched. The couples of sites i,j considered are those coupled by the hamiltonian, for example from tight binding terms.","category":"page"},{"location":"samplers/#","page":"Samplers","title":"Samplers","text":"This rule does preserve total magnetization or particle number, and related symmetries of the hamiltonian.","category":"page"},{"location":"samplers/#Operator-1","page":"Samplers","title":"Operator","text":"","category":"section"},{"location":"samplers/#","page":"Samplers","title":"Samplers","text":"OperatorRule is a transition rule for Metropolis-Hastings sampling where at every step the state is changed to any other state to which it is coupled by an Operator (usually the hamiltonian).","category":"page"},{"location":"samplers/#","page":"Samplers","title":"Samplers","text":"This rule preserves symmetries of the operator.","category":"page"},{"location":"samplers/#Reference-1","page":"Samplers","title":"Reference","text":"","category":"section"},{"location":"samplers/#Samplers-2","page":"Samplers","title":"Samplers","text":"","category":"section"},{"location":"samplers/#","page":"Samplers","title":"Samplers","text":"ExactSampler\nMetropolisSampler","category":"page"},{"location":"samplers/#NeuralQuantum.ExactSampler","page":"Samplers","title":"NeuralQuantum.ExactSampler","text":"ExactSampler(n_samples; seed=rand)\n\nConstructs an exact sampler, which builds the full pdf of the quantum state and samples it exactly.\n\nThis sampler can only be used on indexable spaces, and should be used only for somewhat small systems (Closed N<14, Open N<7), as the computational cost increases exponentially with the number of sites.\n\nInitial seed can be set bu specifying seed.\n\n\n\n\n\n","category":"type"},{"location":"samplers/#NeuralQuantum.MetropolisSampler","page":"Samplers","title":"NeuralQuantum.MetropolisSampler","text":"MetropolisSampler(rule, chain_length, passes; burn=0, seed=rand)\n\nConstructs a Metropolis-Hastings sampler which samples Markov chains of length chain_length + burn, ignoring the first burn samples. Transition rules are specified by the rule rule. To reduce auto-correlation, passes number of metropolis-hastings steps are performed for each sample returned (minimum 1).\n\nEffectively, this means that the chain is actually passes * (chain_lenght + burn) long, but only 1 every passes elements are stored and used to compute expectation values.\n\nInitial seed can be set bu specifying seed.\n\n\n\n\n\n","category":"type"},{"location":"samplers/#","page":"Samplers","title":"Samplers","text":"### Metropolis Rules","category":"page"},{"location":"samplers/#","page":"Samplers","title":"Samplers","text":"LocalRule\nExchangeRule\nOperatorRule","category":"page"},{"location":"samplers/#NeuralQuantum.LocalRule","page":"Samplers","title":"NeuralQuantum.LocalRule","text":"LocalRule()\n\nTransition rule for Metropolis-Hastings sampling where at every step a random site is switched to another random state.\n\n\n\n\n\n","category":"type"},{"location":"samplers/#NeuralQuantum.ExchangeRule","page":"Samplers","title":"NeuralQuantum.ExchangeRule","text":"ExchangeRule(graph)\n\nTransition rule for Metropolis-Hastings sampling where at every step a random couple of sites i,j is switched.\n\nCouples of sites are generated from the graph graph (or operator), where all sites that are connected (or coupled by a 2-body term) are considered for switches.\n\n\n\n\n\n","category":"type"},{"location":"samplers/#NeuralQuantum.OperatorRule","page":"Samplers","title":"NeuralQuantum.OperatorRule","text":"OperatorRule(Ô)\n\nTransition rule for Metropolis-Hastings sampling where at every step a move is drawn from those allowed by the Operator Ô.\n\n\n\n\n\n","category":"type"},{"location":"algorithms/#Algorithms-1","page":"SR","title":"Algorithms","text":"","category":"section"},{"location":"algorithms/#","page":"SR","title":"SR","text":"An algorithm specifies how the loss function is minimised.","category":"page"},{"location":"algorithms/#","page":"SR","title":"SR","text":"We support two types of algorithms: a trivial Gradient Descent and the more sophisticated Stochastic Reconfiguration method.","category":"page"},{"location":"algorithms/#","page":"SR","title":"SR","text":"SR","category":"page"},{"location":"algorithms/#NeuralQuantum.SR","page":"SR","title":"NeuralQuantum.SR","text":"SR([use_iterative=true, ϵ=0.001, λ0=100, b=0.95, λmin=1e-4, [precondition_type=sr_shift, algorithm=sr_qlp, precision=1e-4])\n\nStochastic Reconfiguration preconditioner which corrects the gradient according to the natural gradient computed as S^-1 ∇C. Using this algorithm will lead to the computation of the S matrix together with the gradient of the cost function ∇C. To compute the natural gradient S^-1∇C an iterative scheme (Minres-QLP) or a direct inversion is used.\n\nThe linear system x = S^-1 ∇C is by default solved with minres_qlp iterative solver. Alternatively you can use sr_minres, sr_cg or sr_lsq to use respectively the minres, conjugate gradient and least square solvers from IterativeSolvers.jl. For small systems you can also solve it by computing the pseudo-inverse (sr_diag), the cholesky factorisation (sr_cholesky) the pivoted-cholesky factorisation (sr_pivcholesky), and using the automatic julia solver, usually involving qr decomposition (sr_div). Those non-iterative methods are all from Base.LinearAlgebra.\n\nIf use_iterative=true the inverse matrix S^-1 is not computed, and an iterative MINRES-QLP algorithm is used to compute the product S^-1*F\n\nIf precondition_type=sr_shift then a diagonal uniform shift is added to S S –> S+ϵ*identity\n\nIf precondition_type=sr_multiplicative then a diagonal multiplicative shift is added to S S –> S + max(λ0b^n,λmin)Diagonal(diag(S)) where n is the number of the iteration.\n\n\n\n\n\n","category":"type"}]
}
